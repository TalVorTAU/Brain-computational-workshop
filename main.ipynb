{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d66c362",
   "metadata": {},
   "source": [
    "<b>1. Setup and preprocessing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30f8781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_import_xdf import *\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import ewtpy\n",
    "from ssqueezepy import cwt as ssq_cwt\n",
    "from collections import OrderedDict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import itertools\n",
    "import NeuralNetworks\n",
    "curr_path = pathlib.Path().absolute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfda723",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.1. Set bad electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68873eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_bad_electrodes(subject):\n",
    "    # Define here the subject specific electrodes to make sure are removed from the data: \n",
    "    bad_elecs_dict = {\n",
    "                      'Dekel':{'FT10', 'TP10', 'FT9'},\n",
    "                      'Gilad':{'FT10', 'TP10', 'FT9', 'TP9'},\n",
    "                      'Neta':{'TP9'},\n",
    "                      'Ron-Block':{'PO7'},\n",
    "                      'sub-Roei': {'TP9'},\n",
    "                      'Or': {'FT9','T7','FC2','FT7','Iz'},\n",
    "                      'Roei-MI': {'FT10', 'TP10','P2','AF8','AF7','AF4'},\n",
    "                      'Fudge':{'Iz','FT10', 'TP10', 'FT9', 'TP9','F1'},\n",
    "                      'g': {'T7','CP1','TP9','P7','PO7','O1'},\n",
    "                      'Ron': {'Iz','Cz'}\n",
    "                    }\n",
    "    if subject in bad_elecs_dict.keys():\n",
    "        subject_bad_electrodes=bad_elecs_dict[subject]\n",
    "    else: \n",
    "        subject_bad_electrodes={}\n",
    "        print('Note that no bad electrodes were defined for the current subject:', subject)\n",
    "    return subject_bad_electrodes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b9d4d",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.2. Set parameters for preprocessing (make sure to specify subject name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'Fudge' # Specify the subject name\n",
    "recording_path = curr_path / 'Recordings' / subject_name # Path to the directory containing XDF files\n",
    "# Define the electrode groups: the key can be anything, the values should be a list of electrodes\n",
    "Electrode_Groups = {\n",
    "                    'FP': ['Fp1', 'Fp2'],\n",
    "                    'AF': ['AF7', 'AF3', 'AFz', 'AF4', 'AF8'],\n",
    "                    'F' : ['F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8'],\n",
    "                    'FC': ['FC5', 'FC3', 'FC1', 'FC2', 'FC4', 'FC6'],\n",
    "                    'C' : ['C5', 'C3', 'C1', 'Cz', 'C2', 'C4' ,'C6'],\n",
    "                    'CP': ['CP5', 'CP3','CP1', 'CPz', 'CP2', 'CP4', 'CP6'],\n",
    "                    'P' : ['P7','P5','P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8'],\n",
    "                    'PO': ['PO7','PO3', 'POz', 'PO4', 'PO8'],\n",
    "                    'O' : ['Oz', 'O2', 'O1', 'Iz']\n",
    "                  } \n",
    "\n",
    "params_dict = {\n",
    "          'Electrode_Group': [electrode for group in ['AF', 'F', 'FC', 'C', 'CP', 'P', 'PO'] for electrode in Electrode_Groups[group]], # Electrode groups to include in the analysis\n",
    "          'bad_electrodes': get_subject_bad_electrodes(subject_name),  # Specify bad electrodes for the subject\n",
    "          'low_freq': 0.5,  # High-pass filter frequency cutoff in Hz (frequency below which to filter out)\n",
    "          'high_freq': 50,  # Low-pass filter frequency cutoff in Hz (frequency above which to filter out)\n",
    "          'desired_events': ['ClosePalm','OpenPalm','ActiveRest'],\n",
    "          'filter_method': 'fir',\n",
    "          'epoch_tmin': -4, # Start time of epoch in seconds\n",
    "          'epoch_tmax': 6,  # End time of epoch in seconds\n",
    "          'classifier_window_s': 0.2,\n",
    "          'classifier_window_e': 4.2\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c299d01",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.3. Load XDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf_files = [file for file in recording_path.glob('*.xdf') if subject_name in file.name] # Extracting subject specific XDF files\n",
    "xdf_files[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcb2e5",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.4. Define preprocessing algorithm and event ID (label) standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a7ed4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEG_preprocessing(current_path, raw, params_dict):\n",
    "    \"\"\"\n",
    "    Preprocess EEG data by filtering, removing bad electrodes, and extracting epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        current_path (str): Path to the directory containing XDF files.\n",
    "        raw (mne.io.Raw): MNE Raw object containing EEG data.\n",
    "        params_dict (dict): Dictionary containing preprocessing parameters.\n",
    "    \n",
    "    Returns:\n",
    "        mne.Epochs: Preprocessed epochs object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract parameters from the dictionary\n",
    "    low_freq, high_freq, filter_method, tmin, tmax = params_dict['low_freq'], params_dict['high_freq'], params_dict['filter_method'], params_dict['epoch_tmin'], params_dict['epoch_tmax']\n",
    "    if 'ACC_X' in raw.ch_names:\n",
    "        raw.drop_channels(['ACC_X', 'ACC_Y', 'ACC_Z']) # Drop accelerometer channels if they exist (non-eeg channels)\n",
    "    montage = mne.channels.read_custom_montage(str(current_path / \"Montages\" / \"CACS-64_REF.bvef\"), head_size=0.095, coord_frame=None)\n",
    "    raw.set_montage(montage, match_case=True, match_alias=False, on_missing='raise', verbose=None) # Set montage to the raw data\n",
    "\n",
    "    print('###########################################################' \\\n",
    "    '\\nremoving subject specific bad electrodes from the raw data' \\\n",
    "    '\\n###########################################################' \\\n",
    "    '\\nremoving bad channels from epochs:')\n",
    "\n",
    "    # Remove bad electrodes according to the subject\n",
    "    bad_electrodes = set(raw.info['ch_names']).intersection(params_dict['bad_electrodes']) # Get the intersection of the raw channel names and the bad electrodes for the subject\n",
    "    if len(bad_electrodes) > 0: # If there are bad electrodes, drop them\n",
    "        raw.drop_channels(list(bad_electrodes))\n",
    "    raw.drop_channels(raw.info['bads'])  # Drop any channels marked as bad in the raw info\n",
    "\n",
    "    raw.set_eeg_reference(ref_channels='average')  # Set average reference\n",
    "    mne.set_eeg_reference(raw, copy=False)\n",
    "    print(f'\\n{len(bad_electrodes)} bad electrodes were removed from the raw data: {bad_electrodes}')\n",
    "    print('##########################################################')\n",
    "    \n",
    "    print('\\n Filtering data...')\n",
    "    raw = raw.filter(l_freq=low_freq, h_freq=high_freq, method=filter_method, pad='reflect_limited')\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "    \n",
    "    print('##########################################################' \\\n",
    "        '\\nExtracting event info:', event_dict)\n",
    "    events_trigger_dict = {key: event_dict[key] for key in event_dict.keys() if key in params_dict['desired_events']} # Filter events to keep only the desired ones\n",
    "    print('##########################################################')\n",
    "\n",
    "    selected_electrodes = [elec for elec in params_dict['Electrode_Group'] if elec not in bad_electrodes] # Select electrodes that are not in the bad electrodes list\n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        events_from_annot,\n",
    "        event_id=events_trigger_dict,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "        detrend=0\n",
    "    )\n",
    "    epochs.pick(selected_electrodes)  # Ensure only selected electrodes are kept in the epochs\n",
    "\n",
    "    # Centering the data\n",
    "    centered_data_list = []\n",
    "    events_list = []\n",
    "    mean_across_epochs = epochs.get_data().mean(axis=0)  # Calculate the mean across epochs\n",
    "    # Loop through each event ID\n",
    "    for event_id in params_dict['desired_events']:\n",
    "        print(event_id)\n",
    "        # Extract epochs for the current event\n",
    "        event_epochs = epochs[event_id]\n",
    "        event_data = event_epochs.get_data()\n",
    "\n",
    "        # Calculate the mean across epochs for the current event\n",
    "        mean_across_event_epochs = event_data.mean(axis=0)\n",
    "\n",
    "        # Subtract the mean from each epoch of the current event\n",
    "        centered_event_data = event_data - mean_across_event_epochs\n",
    "\n",
    "        # Store the centered data\n",
    "        centered_data_list.append(centered_event_data)\n",
    "\n",
    "        # Prepare the events list and event_id_map for the combined EpochsArray\n",
    "        events_list.append(event_epochs.events)\n",
    "\n",
    "    # Concatenate all centered data and events\n",
    "    centered_data = np.concatenate(centered_data_list, axis=0)\n",
    "    combined_events = np.concatenate(events_list, axis=0)\n",
    "\n",
    "    # Sort the combined events based on their original occurrence time to preserve the temporal sequence\n",
    "    sorted_indices = np.argsort(combined_events[:, 0])  # Sort by the first column (time)\n",
    "    combined_events = combined_events[sorted_indices]\n",
    "    centered_data = centered_data[sorted_indices]\n",
    "\n",
    "    # Create a new EpochsArray with the centered data\n",
    "    epochs = mne.EpochsArray(\n",
    "        centered_data,\n",
    "        epochs.info,\n",
    "        events=combined_events,\n",
    "        event_id=epochs.event_id,\n",
    "        tmin=epochs.tmin\n",
    "    )\n",
    "\n",
    "    return epochs, mean_across_epochs, events_trigger_dict\n",
    "\n",
    "standard_event_id = {'ActiveRest': 1, 'OpenPalm': 22, 'ClosePalm': 33, 'Rating': 4, 'Rest': 55}\n",
    "\n",
    "def remap_epoch_events_to_standard(epochs, standard_event_id, desired_events):\n",
    "    \"\"\"\n",
    "    Remap event codes to standard event IDs while keeping only desired events\n",
    "    and strictly preserving the original epochs.event_id order.\n",
    "    \n",
    "    Parameters:\n",
    "        epochs (mne.Epochs): The MNE Epochs object containing the original events.\n",
    "        standard_event_id (dict): A dictionary mapping original event names to standard event IDs.\n",
    "        desired_events (list): A list of event names to keep in the epochs.\n",
    "    \n",
    "    Returns:\n",
    "        mne.Epochs: A new MNE Epochs object with remapped events.\n",
    "    \"\"\"\n",
    "    # Copy the original event_id order explicitly\n",
    "    original_order = [key for key in epochs.event_id if key in desired_events]\n",
    "\n",
    "    # Create mappings from old numeric codes to labels\n",
    "    val_to_label = {val: label for label, val in epochs.event_id.items()}\n",
    "\n",
    "    # Remap numeric event codes to standard_event_id values explicitly\n",
    "    for i, code in enumerate(epochs.events[:, 2]):\n",
    "        label = val_to_label[code]\n",
    "        epochs.events[i, 2] = standard_event_id[label]\n",
    "\n",
    "    # Reconstruct epochs.event_id preserving the original order explicitly\n",
    "    epochs.event_id = OrderedDict((label, standard_event_id[label]) for label in original_order)\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af6d1d",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.5. Perform preprocessing and event ID (label) standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7670bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = []\n",
    "for xdf_file in xdf_files:\n",
    "    print(f'Processing file: {xdf_file}')\n",
    "    raw = read_raw_xdf(xdf_file)\n",
    "    epochs, mean_across_epochs, _ = EEG_preprocessing(curr_path, raw, params_dict)\n",
    "    epochs = remap_epoch_events_to_standard(epochs, standard_event_id, params_dict['desired_events'])\n",
    "\n",
    "    # Update events_trigger_dict to match new labels\n",
    "    events_trigger_dict = {event: standard_event_id[event] for event in params_dict['desired_events']}\n",
    "    epochs_list.append(epochs)\n",
    "print('Concatenating all preprocessed epochs...')\n",
    "epochs = mne.concatenate_epochs(epochs_list, on_mismatch='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metadata\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dbe8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for channel names and their corresponding indices\n",
    "channel_indices = {ch_name: idx for idx, ch_name in enumerate(epochs.ch_names)}\n",
    "# Create arrays of electrode names\n",
    "motor_cortex_electrodes = ['C5', 'C3', 'C1', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CP2', 'CP4', 'CP6', 'P5', 'P3', 'P1', 'P2', 'P4', 'P6']\n",
    "basic_three_electrodes = ['C3', 'Cz', 'C4']\n",
    "frontal_electrodes =['F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']\n",
    "# Create arrays of channel indices for each of the electrode names arrays\n",
    "motor_cortex_indices = [channel_indices[ch] for ch in motor_cortex_electrodes if ch in channel_indices]\n",
    "basic_three_indices = [channel_indices[ch] for ch in basic_three_electrodes if ch in channel_indices]\n",
    "motor_and_frontal_indices = motor_cortex_indices + [channel_indices[ch] for ch in frontal_electrodes if ch in channel_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9efbeb",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.6. Balance classes by subsampling classes to match size of smallest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6c07be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_epochs_by_subsampling(epochs):\n",
    "    \"\"\"\n",
    "    Subsamples the specified class to match the smallest number of epochs in other classes.\n",
    "\n",
    "    Parameters:\n",
    "        epochs (mne.Epochs): MNe Epochs object with labeled events (e.g., 'Rest', 'OpenPalm', 'ClosePalm')\n",
    "        class_to_subsample (string): class label to downsample.\n",
    "    \n",
    "    Returns:\n",
    "        mne.Epochs: new Epochs object with balanced classes.\n",
    "    \"\"\"\n",
    "\n",
    "    event_id = epochs.event_id\n",
    "    all_classes = list(event_id.keys())\n",
    "\n",
    "    # Count epochs in each class\n",
    "    class_counts = {label: len(epochs[label]) for label in all_classes}\n",
    "    min_count = min(class_counts.values()) # Find the minimum count among the classes\n",
    "\n",
    "    # Get indices to keep\n",
    "    selected_indices = []\n",
    "    for label in all_classes:\n",
    "        picks = epochs[label].selection\n",
    "        if class_counts[label] > min_count:\n",
    "            picks = np.random.choice(picks, min_count, replace=False)  # Randomly select indices for the class to subsample\n",
    "        selected_indices.extend(picks)\n",
    "\n",
    "    # Sort indices and return the new subset\n",
    "    epochs = epochs[np.sort(selected_indices)]\n",
    "\n",
    "    return epochs\n",
    "\n",
    "epochs = balance_epochs_by_subsampling(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad235474",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;1.7. Crop epoch timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b4738ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs.crop(tmin=float(params_dict['classifier_window_s']), tmax=float(params_dict['classifier_window_e']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994165a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; 1.8. Define dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14dc70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.get_data()  # Get the data from the epochs\n",
    "Y = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519b5a4",
   "metadata": {},
   "source": [
    "<b>2. MSPCA: Signal denoising</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a492c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSPCA(X, n_decomps=5):\n",
    "    \"\"\"\n",
    "    Perform Multiscale Principal Component Analysis on the input data X.\n",
    "    \n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Input data of shape (n_epochs, n_channels, n_samples).\n",
    "        n_decomps (int): Number of decomposition levels for EWT (Default is 5 as it is supported by literature).\n",
    "    \n",
    "    Returns:\n",
    "        denoised_X (numpy.ndarray): Denoised data (of the same shape as original data) after applying MSPCA.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_epochs, n_channels, n_samples = X.shape\n",
    "    X_denoised = np.zeros_like(X)\n",
    "    for epoch in range(n_epochs):\n",
    "        # Step 1: Decompose each signal (channel) in the epoch using EWT\n",
    "        ewt_coeffs = np.zeros((n_channels, n_decomps, n_samples))\n",
    "        mfb_values = []\n",
    "        for channel in range(n_channels):\n",
    "            signal = X[epoch, channel, :]\n",
    "            ewt, mfb, _ = ewtpy.EWT1D(signal, N=n_decomps)\n",
    "            ewt_coeffs[channel, :, :] = ewt.T # ewt.shape == (n_samples, n_decomps), ewt_coeffs.shape[channel, :, :] == (n_decomps, n_samples) \n",
    "            mfb_values.append(mfb)\n",
    "        \n",
    "        # Step 2: Perform PCA on each level/mode/subband across all channels\n",
    "        denoised_ewt_coeffs = np.zeros_like(ewt_coeffs)\n",
    "        for level in range(n_decomps):\n",
    "            level_data = ewt_coeffs[:, level, :].T # Shape (n_samples, n_channels)\n",
    "            # Perform PCA\n",
    "            pca = PCA()\n",
    "            level_data_pca = pca.fit_transform(level_data)\n",
    "            # Apply Kaiser's rule (keep components of eigenvalues >= mean_eigenvalue)\n",
    "            mean_eigenvalue = np.mean(pca.explained_variance_)\n",
    "            n_components_to_keep = np.sum(pca.explained_variance_ >= mean_eigenvalue)\n",
    "            level_data_pca[:, n_components_to_keep:] = 0  # Set components below the mean eigenvalue to zero, effectively removing unwanted PCs\n",
    "            denoised_ewt_coeffs[:, level, :] = pca.inverse_transform(level_data_pca).T # Inverse transform to get back to the original space, shape (n_channels, n_samples)\n",
    "        \n",
    "        # Step 3: Reconstruct the denoised signals \n",
    "        for channel in range(n_channels):\n",
    "            ewt = denoised_ewt_coeffs[channel, :, :] # This instance of ewt is of shape (n_decomps, n_samples)\n",
    "            slice_index = int(np.ceil(n_samples / 2)) \n",
    "            mfb = mfb_values[channel].T[:, slice_index - 1: -slice_index] # mfb_values[channel].T is of shape (n_samples*2, n_decomps)\n",
    "            real = all(np.isreal(ewt[0]))\n",
    "            if real: \n",
    "                reconstructed_signal = np.zeros(ewt.shape[1])\n",
    "                for i in range(0, ewt.shape[0]):\n",
    "                    reconstructed_signal += np.real(np.fft.ifft(np.fft.fft(ewt[i]) * mfb[i]))\n",
    "            else:\n",
    "                reconstructed_signal = np.zeros(ewt.shape[1]) * 0j\n",
    "                for i in range(0, ewt.shape[0]):\n",
    "                    reconstructed_signal += np.fft.ifft(np.fft.fft(ewt[i]) * mfb[i])\n",
    "            X_denoised[epoch, channel, :] = reconstructed_signal\n",
    "        \n",
    "        # Step 4: Perform global PCA on the reconstructed signals\n",
    "        pca = PCA()\n",
    "        reconstructed_epoch = X_denoised[epoch, :, :].T\n",
    "        reconstructed_epoch_pca = pca.fit_transform(reconstructed_epoch)\n",
    "        # Apply Kaiser's rule (keep components of eigenvalues >= mean_eigenvalue)\n",
    "        mean_eigenvalue = np.mean(pca.explained_variance_)\n",
    "        n_components_to_keep = np.sum(pca.explained_variance_ >= mean_eigenvalue)\n",
    "        reconstructed_epoch_pca[:, n_components_to_keep:] = 0  # Set components below the mean eigenvalue to zero, effectively removing unwanted PCs\n",
    "        X_denoised[epoch, :, :] = pca.inverse_transform(reconstructed_epoch_pca).T\n",
    "    \n",
    "    return X_denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3d94c",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">2.1. Perform MSPCA denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56698854",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_denoised = MSPCA(X)  # Denoise data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cba10",
   "metadata": {},
   "source": [
    "Sanity check (No need to run the following code cell for pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4043d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "print(X_denoised.shape, X.shape)\n",
    "print(f\"Size: {X.nbytes / 1024**2:.2f} MB\")\n",
    "print(f\"Size: {X_denoised.nbytes / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9a503",
   "metadata": {},
   "source": [
    "Back to real code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5dd3c8",
   "metadata": {},
   "source": [
    "<b>3. Continuous Wavelet Transform (CWT) for transformation of data into scalograms</b>\n",
    "<div style=\"margin-left: 30px;\">CWT Turns 1D signal into a time-frequency (2D) signal that can be turned into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204afa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Scalograms', exist_ok=True)  # Create directory for scalograms if it doesn't exist\n",
    "def cwt_transform(data, wavelet='morse', scales=None, samp_period=1/500, ssq_gamma=3, ssq_beta=60):\n",
    "    \"\"\"\n",
    "    Apply Continuous Wavelet Transform (CWT) to the EEG data using either pywt (morlet) or ssqueezepy (morse).\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy.ndarray or mne.Epochs): EEG data of shape (n_epochs, n_channels, n_times).\n",
    "        wavelet (str): 'morlet' for pywt or 'morse' for ssqueezepy.\n",
    "        scales (numpy.ndarray): Scales for the CWT. If None, default scales will be used.\n",
    "        samp_period (float): Sampling period (1/sampling frequency).\n",
    "        ssq_gamma (float): Morse wavelet gamma parameter (ssqueezepy only).\n",
    "        ssq_beta (float): Morse wavelet beta parameter (ssqueezepy only).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed data after applying CWT.\n",
    "    \"\"\"\n",
    "    if scales is None:\n",
    "        scales = np.arange(8.125, 812.5, 8.125)  # Default scales (0.5Hz to 50Hz when sampling rate == 500Hz)\n",
    "\n",
    "    coeffs_mtrx = []\n",
    "    freqs_mtrx = []\n",
    "    if isinstance(data, mne.Epochs):\n",
    "        data = data.get_data()  # Convert MNE Epochs to numpy array if needed\n",
    "\n",
    "    for epoch in data:\n",
    "        cwt_coeffs_matrices = []\n",
    "        cwt_freqs_matrices = []\n",
    "        for channel in epoch:\n",
    "            if wavelet == 'morlet':\n",
    "                coeffs, freqs = pywt.cwt(channel, scales, 'morl', sampling_period=samp_period)\n",
    "            elif wavelet == 'morse':\n",
    "                Wx, ssq_scales = ssq_cwt(channel, wavelet=('gmw', {'gamma': ssq_gamma, 'beta': ssq_beta}))\n",
    "                coeffs = Wx\n",
    "                # Convert scales to pseudo-frequencies (Hz) [not relevant for Morse wavelets]\n",
    "                freqs = ssq_scales\n",
    "            cwt_coeffs_matrices.append(coeffs)\n",
    "            cwt_freqs_matrices.append(freqs)\n",
    "        coeffs_mtrx.append(np.array(cwt_coeffs_matrices))\n",
    "        freqs_mtrx.append(np.array(cwt_freqs_matrices))\n",
    "    coeffs_mtrx = np.array(coeffs_mtrx)  # Convert list to numpy array\n",
    "    freqs_mtrx = np.array(freqs_mtrx)    # Convert list to numpy array\n",
    "    return coeffs_mtrx, freqs_mtrx\n",
    "\n",
    "event_id_name = {1: 'ActiveRest' , 22: 'OpenPalm', 33: 'ClosePalm', 4: 'Rating', 55: 'Rest'}\n",
    "\n",
    "def save_scalogram(coeffs, freqs, epoch_index=0, epoch_offset=0, channel_index=0, path='Scalograms', close=True, detailed=False):\n",
    "    \"\"\"\n",
    "    Creates scalogram for a specific epoch and channel.\n",
    "    \n",
    "    Parameters:\n",
    "        coeffs (numpy.ndarray): CWT coefficients of shape (n_epochs, n_channels, n_scales, n_times).\n",
    "        freqs (numpy.ndarray): Frequencies or scales corresponding to the coefficients.\n",
    "        epoch_index (int): Index of the epoch to plot.\n",
    "        epoch_offset (int): Offset to adjust the epoch index for saving.\n",
    "        channel_index (int): Index of the channel to plot.\n",
    "        path (str): Path to save the scalogram image.\n",
    "        close (bool): Whether to close the plot after saving.\n",
    "        detailed (bool): Whether to save a detailed scalogram with axes and labels.\n",
    "\n",
    "    Returns:\n",
    "        None: Saves the scalogram image to the specified path.\n",
    "    \"\"\"\n",
    "    \n",
    "    if detailed:\n",
    "        # Create path if it doesn't exist\n",
    "        os.makedirs(path + '/Detailed', exist_ok=True)\n",
    "        \n",
    "        # Saving detailed scalogram\n",
    "        plt.figure()\n",
    "        plt.imshow(np.abs(coeffs[epoch_index, channel_index]), extent=[0, coeffs.shape[-1], freqs[epoch_index][channel_index][0], freqs[epoch_index][channel_index][-1]], aspect='auto', cmap='jet')\n",
    "        plt.colorbar(label='Magnitude')\n",
    "        plt.title(f'Scalogram for Epoch {epoch_index + epoch_offset} ({event_id_name[Y[epoch_index + epoch_offset]]}), Channel {channel_index} ({epochs.ch_names[channel_index]})')\n",
    "        plt.xlabel('Time (samples)')\n",
    "        plt.ylabel('Frequency (Hz) / Scales')\n",
    "        plt.savefig(f'{path}/Detailed/epoch_{epoch_index + epoch_offset}-channel_{channel_index}.png', bbox_inches='tight', pad_inches=0)\n",
    "        if close:\n",
    "            plt.close()\n",
    "\n",
    "    # Saving clean scalogram\n",
    "    os.makedirs(path + '/Clean', exist_ok=True)\n",
    "    plt.figure(figsize=(2.90, 2.91))\n",
    "    plt.imshow(np.abs(coeffs[epoch_index, channel_index]), extent=[0, coeffs.shape[-1], freqs[epoch_index][channel_index][0], freqs[epoch_index][channel_index][-1]], aspect='auto', cmap='jet')\n",
    "    plt.axis('off')  # Turn off the axis\n",
    "    plt.savefig(f'{path}/Clean/epoch_{epoch_index + epoch_offset}-channel_{channel_index}.png', dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def scalogram_transform_and_save(dataset, wavelet='morse', save_path = 'Scalograms', chunks=1):\n",
    "    '''\n",
    "    Transform dataset to scalogram using Continuous Wavelet Transform (CWT), either with morlet mother wavelet or generalized morse wavelets.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (numpy.ndarray): EEG data of shape (n_epochs, n_channels, n_times).\n",
    "        data_type (str): 'Noisy' or 'Denoised' to specify the type of data being transformed.\n",
    "        wavelet (str): Wavelet parameter of the CWT algorithm ('morlet' or 'morse').\n",
    "        save_path (str): Path to save the scalograms.\n",
    "        chunks (int): Number of chunks to split the dataset into for processing (to avoid memory allocation issues). Default is 1 (process the entire dataset at once).\n",
    "\n",
    "    Return:\n",
    "        None.\n",
    "    '''\n",
    "    intervals = np.linspace(0, dataset.shape[0], chunks + 1, dtype=int)\n",
    "    offset = 0\n",
    "    for i in range(chunks):\n",
    "        X = dataset[intervals[i] : intervals[i + 1]] # Portion of the dataset to transfrom using CWT\n",
    "        offset = intervals[i]\n",
    "        # CWT on data portion\n",
    "        if wavelet == 'morlet':\n",
    "            cwt_coeffs, cwt_freqs = cwt_transform(X, wavelet='morlet', scales=pywt.frequency2scale('morl', (np.arange(8, 30.1, 0.1) / epochs.info['sfreq'])), samp_period=1/epochs.info['sfreq'])\n",
    "        elif wavelet == 'morse':\n",
    "            cwt_coeffs, cwt_freqs = cwt_transform(X, wavelet='morse', samp_period=1/epochs.info['sfreq'], ssq_gamma=3, ssq_beta=60)\n",
    "            scales_size = cwt_coeffs.shape[2]\n",
    "            # Cropping top and bottom 1/4 of the scales because they don't contain any useful information\n",
    "            cwt_coeffs = cwt_coeffs[:, :, scales_size // 4: scales_size - (scales_size // 4), :]\n",
    "            cwt_freqs = cwt_freqs[:, :, scales_size // 4: scales_size - (scales_size // 4)]\n",
    "\n",
    "        \n",
    "        # Save the scalograms\n",
    "        for epoch in range(X.shape[0]):\n",
    "            for channel in range(X.shape[1]):\n",
    "                save_scalogram(cwt_coeffs, cwt_freqs, epoch_index=epoch, epoch_offset=offset, channel_index=channel, path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948adbe",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">3.1. <b> Choose from two options</b>: pywt's CWT function (using <u><i>morlet mother wavelet</i></u>) or ssquuezepy's CWT function (using <u><i>generalized morse wavelets</i></u>). <br> \n",
    "Empirical research shows a clear preference for morse wavelets when performing CWT, pointing to better time-frequency localization. <br>\n",
    "Also, due to memory limitations, choose whether to continue running the pipeline with noisy or with denoised data. For the same reason, we split the process into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfc9cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'Denoised' # 'Denoised' or 'Noisy'\n",
    "wavelet = 'morse' # 'morse' or 'morlet'\n",
    "save_path = 'Scalograms/' + data_type + '/All Data' # Path to save scalograms for entire dataset\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "chunks = 9 # Number of chunks to split the data into for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4b0cb",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">3.2. Perform CWT on dataset (noisy or denoised) and save as scalograms in storage (may take over an hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fca861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'Denoised':\n",
    "    X = X_denoised\n",
    "elif data_type == 'Noisy':\n",
    "    if 'X_denoised' in locals() or 'X_denoised' in globals():\n",
    "        del X_denoised\n",
    "scalogram_transform_and_save(X, wavelet=wavelet, save_path=save_path, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94489d",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">3.3. Create a file containing mappings from epochs to labels for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7246b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: {'ActiveRest': 30, 'OpenPalm': 30, 'ClosePalm': 30}\n",
      "ClosePalm\n"
     ]
    }
   ],
   "source": [
    "# Create epoch to class mappings for training set\n",
    "epoch_class_mapping = {}\n",
    "for epoch_idx in range(len(Y)):\n",
    "    class_label = event_id_name[Y[epoch_idx]]\n",
    "    epoch_class_mapping[epoch_idx] = class_label\n",
    "\n",
    "# Create summary statistics\n",
    "class_counts = {}\n",
    "classes = ['ActiveRest', 'OpenPalm', 'ClosePalm']\n",
    "for class_name in classes:\n",
    "    class_counts[class_name] = sum(1 for label in epoch_class_mapping.values() if label == class_name)\n",
    "\n",
    "# Save the mappings and statistics\n",
    "epoch_mappings = {\n",
    "    'epoch_to_class': epoch_class_mapping,\n",
    "    'class_counts': class_counts,\n",
    "    'classes': classes,\n",
    "    'total_epochs_size': len(epoch_class_mapping)\n",
    "}\n",
    "\n",
    "# Save as numpy file for easy loading\n",
    "np.save('epoch_class_mappings.npy', epoch_mappings)\n",
    "\n",
    "print(f\"Dataset: {class_counts}\")\n",
    "print(epoch_mappings['epoch_to_class'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f058a",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09a9b2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActiveRest indices: [0, 3, 5, 7, 8, 10, 12, 13, 21, 23, 24, 26, 30, 31, 33, 34, 38, 39, 42, 52, 54, 58, 59, 61, 68, 73, 75, 76, 79, 89]\n",
      "ClosePalm indices:  [2, 4, 9, 15, 18, 25, 27, 28, 32, 36, 41, 43, 45, 49, 51, 53, 56, 60, 65, 69, 70, 72, 78, 80, 81, 82, 84, 85, 86, 88]\n",
      "OpenPalm indices:   [1, 6, 11, 14, 16, 17, 19, 20, 22, 29, 35, 37, 40, 44, 46, 47, 48, 50, 55, 57, 62, 63, 64, 66, 67, 71, 74, 77, 83, 87]\n",
      "(90, 48, 2001)\n"
     ]
    }
   ],
   "source": [
    "ActiveRest = []\n",
    "ClosePalm = []\n",
    "OpenPalm = []\n",
    "for i in range(len(Y)):\n",
    "    if event_id_name[Y[i]] == 'ActiveRest':\n",
    "        ActiveRest.append(i)\n",
    "    elif event_id_name[Y[i]] == 'ClosePalm':\n",
    "        ClosePalm.append(i)\n",
    "    elif event_id_name[Y[i]] == 'OpenPalm':\n",
    "        OpenPalm.append(i)\n",
    "    else:\n",
    "        print(f'Unexpected label {Y[i]} at index {i}')\n",
    "\n",
    "print(\"ActiveRest indices:\", ActiveRest)\n",
    "print(\"ClosePalm indices: \", ClosePalm)\n",
    "print(\"OpenPalm indices:  \", OpenPalm)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6f009",
   "metadata": {},
   "source": [
    "<b>4. Stacking and resizing of scalograms</b>\n",
    "<div style=\"margin-left: 30px;\">Here we process and adapt the scalograms to the neural netwrok specifications (for example: Shufflenet requires images of size 224x224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb56f06",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">4.1. Import epoch ID to class mappings from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8b1fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 'ClosePalm']\n"
     ]
    }
   ],
   "source": [
    "epoch_mappings = np.load('epoch_class_mappings.npy', allow_pickle=True).item()\n",
    "# Create a DataFrame from the epoch mappings\n",
    "full_dataset = pd.DataFrame.from_dict(epoch_mappings['epoch_to_class'], orient='index', columns=['label'])\n",
    "full_dataset = full_dataset.reset_index().rename(columns={'index': 'epoch_id'})\n",
    "print(full_dataset.loc[full_dataset['epoch_id'] == 2].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c54c0",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">4.2. Choose whether to proceed with noisy data or denoised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c379c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'Denoised' # 'Denoised' or 'Noisy'\n",
    "os.makedirs('Scalograms/' + data_type + '/All Data/Stacked scalograms', exist_ok=True) # Create directory for stacked and resized scalograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e315d",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">4.3. Define function that combines scalograms from different channels into one image for each epoch.  \n",
    "The function can stack them vertically or horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_scalograms(image_paths, output_path, plane='vertical', target_size=None):\n",
    "    \"\"\"\n",
    "    Stack multiple scalograms (PNG images) vertically/horizontally.\n",
    "    \n",
    "    Parameters:\n",
    "        image_paths (list): List of paths to the PNG images\n",
    "        output_path (str): Path where the combined image will be saved\n",
    "        plane (str): 'vertical' or 'horizontal' to specify the stacking direction\n",
    "        target_size (tuple): Optional target size (width, height) to resize the combined image before saving\n",
    "    \"\"\"\n",
    "    # Read all images\n",
    "    images = [cv2.imread(path) for path in image_paths]\n",
    "    if plane == 'vertical':\n",
    "        # Get the minimum width to resize all images to the same width\n",
    "        min_width = min(img.shape[1] for img in images)\n",
    "        \n",
    "        # Resize images to have the same width\n",
    "        resized_images = []\n",
    "        for img in images:\n",
    "            if img.shape[1] != min_width:\n",
    "                aspect_ratio = img.shape[0] / img.shape[1]\n",
    "                new_height = int(min_width * aspect_ratio)\n",
    "                resized_img = cv2.resize(img, (min_width, new_height))\n",
    "            else:\n",
    "                resized_img = img\n",
    "            resized_images.append(resized_img)\n",
    "        \n",
    "        # Stack vertically\n",
    "        combined_image = cv2.vconcat(resized_images)\n",
    "    \n",
    "    if plane == 'horizontal':\n",
    "        # Get the minimum height to resize all images to the same height\n",
    "        min_height = min(img.shape[0] for img in images)\n",
    "    \n",
    "        # Resize images to have the same height\n",
    "        resized_images = []\n",
    "        for img in images:\n",
    "            if img.shape[0] != min_height:\n",
    "                aspect_ratio = img.shape[1] / img.shape[0]\n",
    "                new_width = int(min_height * aspect_ratio)\n",
    "                resized_img = cv2.resize(img, (new_width, min_height))\n",
    "            else:\n",
    "                resized_img = img\n",
    "            resized_images.append(resized_img)\n",
    "\n",
    "        # Stack horizontally\n",
    "        combined_image = cv2.hconcat(resized_images)\n",
    "    \n",
    "    # Save the combined image (resize if necessary)\n",
    "    if target_size != None:\n",
    "        combined_image = cv2.resize(combined_image, target_size)\n",
    "    cv2.imwrite(output_path, combined_image)\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce2f9c",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">4.4. Choose <b>ONE</b> of the following options:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515dd8e",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 40px;\"> <b><u>Option 1</u></b>: Considering the limited size of the CNN input (224x224) and the size of bandwidth (Mu + Beta = 8Hz-30Hz) and trial duration (4s after crop) <br> we start small and only combine 3 scalograms: C3, Cz, C4.\n",
    "<br><br>\n",
    "<u><b>Option 2</b></u>: A more advanced approach that includes more channels with the hope of improving data quality. <br> We are going to combine 18 scalograms from motor cortex channels C5, C3, C1, C2, C4, C6, CP5, CP3, CP1, CP2, CP4, CP6, P5, P3, P1, P2, P4, P6.<br>First, we will vertically stack each half of the 18 images, resulting in 2 stacked images. <br>\n",
    "Then, we will horizontally stack the 2 images and create one stacked image of size 2 [scalograms] by 9 [scalograms].\n",
    "<br><br>\n",
    "<u><b>Option 3</b></u>: Experimental approach which includes the frontal channels on top of the 18 motor cortex channels of the previous option. <br> The channels are: C5, C3, C1, C2, C4, C6, CP5, CP3, CP1, CP2, CP4, CP6, P5, P3, P1, P2, P4, P6, F7, F5, F3, F1, Fz, F2, F4, F6, F8. <br> \n",
    "The final image will be a 3 by 9 stacked image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a0ff1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_option = 3 #1, 2, or 3\n",
    "resize = (224, 224) # Resize the stacked scalograms to this size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_option == 1:\n",
    "    for i in range(full_dataset.shape[0]):\n",
    "        image_paths = []\n",
    "        for j in basic_three_indices:\n",
    "            image_paths.append('Scalograms/' + data_type + f'/All Data/Clean/epoch_{i}-channel_{j}.png')\n",
    "        stack_scalograms(image_paths, 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-channels_{\"_\".join(map(str, basic_three_indices))}.png', plane='vertical', target_size=resize)\n",
    "    file_pattern = 'channels_20_22_24.png'\n",
    "if chosen_option == 2:\n",
    "    for i in range(full_dataset.shape[0]):\n",
    "        image_paths1 = []\n",
    "        image_paths2 = []\n",
    "        for k, j in enumerate(motor_cortex_indices):\n",
    "            if k < len(motor_cortex_indices) // 2:\n",
    "                image_paths1.append('Scalograms/' + data_type + f'/All Data/Clean/epoch_{i}-channel_{j}.png')\n",
    "            else:\n",
    "                image_paths2.append('Scalograms/' + data_type + f'/All Data/Clean/epoch_{i}-channel_{j}.png')\n",
    "        output_path1 = 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-channels_{\"_\".join(map(str, motor_cortex_indices[:len(motor_cortex_indices) // 2]))}.png'\n",
    "        output_path2 = 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-channels_{\"_\".join(map(str, motor_cortex_indices[len(motor_cortex_indices) // 2:]))}.png'\n",
    "        # Stack the first half of channels vertically\n",
    "        stack_scalograms(image_paths1, output_path1, plane='vertical')\n",
    "        # Stack the second half of channels vertically\n",
    "        stack_scalograms(image_paths2, output_path2, plane='vertical')\n",
    "        # Stack the two halves horizontally\n",
    "        stack_scalograms([output_path1, output_path2], 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-18_motor_cortex_channels.png', plane='horizontal', target_size=resize)\n",
    "        # Delete the intermediate images\n",
    "        os.remove(output_path1)\n",
    "        os.remove(output_path2)\n",
    "    file_pattern = '18_motor_cortex_channels.png'\n",
    "if chosen_option == 3:\n",
    "    for i in range(full_dataset.shape[0]):\n",
    "        image_paths1 = []\n",
    "        image_paths2 = []\n",
    "        image_paths3 = []\n",
    "        for k, j in enumerate(motor_and_frontal_indices):\n",
    "            if k < len(motor_and_frontal_indices) // 3:\n",
    "                image_paths1.append('Scalograms/' + data_type + f'/All Data/Clean/epoch_{i}-channel_{j}.png')\n",
    "            elif k < 2 * len(motor_and_frontal_indices) // 3:\n",
    "                image_paths2.append('Scalograms/' + data_type + f'/All Data/Clean/epoch_{i}-channel_{j}.png')\n",
    "            else:\n",
    "                image_paths3.append('Scalograms/' + data_type + f'/All Data/Clean/epoch_{i}-channel_{j}.png')\n",
    "        output_path1 = 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-channels_{\"_\".join(map(str, motor_and_frontal_indices[:len(motor_and_frontal_indices) // 3]))}.png'\n",
    "        output_path2 = 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-channels_{\"_\".join(map(str, motor_and_frontal_indices[len(motor_and_frontal_indices) // 3:2 * len(motor_and_frontal_indices) // 3]))}.png'\n",
    "        output_path3 = 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-channels_{\"_\".join(map(str, motor_and_frontal_indices[2 * len(motor_and_frontal_indices) // 3:]))}.png'\n",
    "        # Stack the first third of channels vertically\n",
    "        stack_scalograms(image_paths1, output_path1, plane='vertical')\n",
    "        # Stack the second third of channels vertically\n",
    "        stack_scalograms(image_paths2, output_path2, plane='vertical')\n",
    "        # Stack the last third of channels vertically\n",
    "        stack_scalograms(image_paths3, output_path3, plane='vertical')\n",
    "        # Stack the three thirds horizontally\n",
    "        stack_scalograms([output_path1, output_path2, output_path3], 'Scalograms/' + data_type + f'/All Data/Stacked scalograms/epoch_{i}-27_motor_and_frontal_channels.png', plane='horizontal', target_size=resize)\n",
    "        # Delete the intermediate images\n",
    "        os.remove(output_path1)\n",
    "        os.remove(output_path2)\n",
    "        os.remove(output_path3)\n",
    "    file_pattern = '27_motor_and_frontal_channels.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e2344",
   "metadata": {},
   "source": [
    "<b>5. Nested cross validation pipeline of CNN transfer learning.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a711bc",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">5.1. Choose the <u>model</u> and classification <u>classes</u> (<i> 'ActiveRest vs. ClosePalm' / 'ActiveRest vs. OpenPalm' / 'ClosePalm vs. OpenPalm' / 'All classes'</i>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cef1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'shufflenet_v2'  # 'alexnet', 'shufflenet_v2', 'convnext_t', 'convnext_s' or 'efficientnet_v2'\n",
    "chosen_classes = ['ClosePalm', 'OpenPalm'] # ['ActiveRest', 'ClosePalm'] or ['ActiveRest', 'OpenPalm'] or ['ClosePalm', 'OpenPalm'] or ['ActiveRest', 'ClosePalm', 'OpenPalm']\n",
    "\n",
    "if len(chosen_classes) == 2:\n",
    "    class_mappings = {chosen_classes[0]: 'A', chosen_classes[1]: 'B'} # Mapping for the classes to be used in the cross-validation\n",
    "    dataset = full_dataset[full_dataset['label'].isin(chosen_classes)].reset_index(drop=True)\n",
    "else: \n",
    "    dataset = full_dataset.copy()\n",
    "cv_path = 'Scalograms/' + data_type\n",
    "os.makedirs(cv_path + '/Test/A', exist_ok=True)\n",
    "os.makedirs(cv_path + '/Test/B', exist_ok=True)\n",
    "if len(chosen_classes) == 3:\n",
    "    os.makedirs(cv_path + '/Test/C', exist_ok=True)\n",
    "else:\n",
    "    shutil.rmtree(cv_path + '/Test/C', ignore_errors=True)\n",
    "os.makedirs(cv_path + '/Outer Train', exist_ok=True)\n",
    "os.makedirs(cv_path + '/Outer Train/All Train', exist_ok=True)\n",
    "os.makedirs(cv_path + '/Outer Train/Train/A', exist_ok=True)\n",
    "os.makedirs(cv_path + '/Outer Train/Train/B', exist_ok=True)\n",
    "if len(chosen_classes) == 3:\n",
    "    os.makedirs(cv_path + '/Outer Train/Train/C', exist_ok=True)\n",
    "else:\n",
    "    shutil.rmtree(cv_path + '/Outer Train/Train/C', ignore_errors=True)\n",
    "os.makedirs(cv_path + '/Outer Train/Valid/A', exist_ok=True)\n",
    "os.makedirs(cv_path + '/Outer Train/Valid/B', exist_ok=True)\n",
    "if len(chosen_classes) == 3:\n",
    "    os.makedirs(cv_path + '/Outer Train/Valid/C', exist_ok=True)\n",
    "else:\n",
    "    shutil.rmtree(cv_path + '/Outer Train/Valid/C', ignore_errors=True)\n",
    "os.makedirs('Results', exist_ok=True)\n",
    "\n",
    "def move_epochs(X, epoch_indices, src_folder, dst_folder, file_pattern, copy=False):\n",
    "    '''\n",
    "    Moves or copies files corresponding to the specified epoch indices from the source folder to the destination folder.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Array of epoch data.\n",
    "        epoch_indices (list): List of indices of epochs to move or copy.\n",
    "        src_folder (str): Path to the source folder containing the files.\n",
    "        dst_folder (str): Path to the destination folder where files will be moved or copied.\n",
    "        file_pattern (str): Pattern for the filenames, e.g., 'epoch_{}.png'.\n",
    "        copy (bool): If True, copies files; if False, moves files.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "    '''\n",
    "    os.makedirs(dst_folder, exist_ok=True)\n",
    "    for idx in epoch_indices:\n",
    "        src_path = os.path.join(src_folder, file_pattern.format(X[idx]))\n",
    "        dst_path = os.path.join(dst_folder, file_pattern.format(X[idx]))\n",
    "        if os.path.exists(src_path):\n",
    "            if copy:\n",
    "                shutil.copy(src_path, dst_path)\n",
    "            else:\n",
    "                shutil.move(src_path, dst_path)\n",
    "\n",
    "def delete_all_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Deletes all files in the specified folder.\n",
    "    \n",
    "    Parameters:\n",
    "        directory (str): Path to the directory from which files will be deleted\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bcb86",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 30px;\">5.2. Execute 5x4 nested cross-validation and save results. <br>\n",
    "<i> Note.</i> If the code gets interrupted, make sure all cross validation directories are empty before running again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['epoch_id'].values\n",
    "y = dataset['label'].values\n",
    "stack_type = ['3 Channels', '18 Channels', '27 Channels']\n",
    "if len(chosen_classes) == 2:\n",
    "    results_path = f'Results/{subject_name}/{stack_type[chosen_option - 1]}/{model_name}/{chosen_classes[0]} vs. {chosen_classes[1]}'\n",
    "else:\n",
    "    results_path = f'Results/{subject_name}/{stack_type[chosen_option - 1]}/{model_name}/all classes'\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters to test\n",
    "optimizers = ['adamw', 'rmsprop', 'sgdm']\n",
    "learning_rates = [0.001, 0.0001]\n",
    "batch_sizes = [8, 16, 32]\n",
    "\n",
    "# Create a DataFrame to store the results of the inner cross-validation\n",
    "inner_results = pd.DataFrame(list(itertools.product(optimizers, learning_rates, batch_sizes)), columns=['optimizer', 'learning_rate', 'batch_size'])\n",
    "final_model_mean_accuracy = 0.0\n",
    "\n",
    "# Perform 5x4 nested cross-validation\n",
    "for i, (outer_train_indices, test_indices) in enumerate(outer_cv.split(X, y)):\n",
    "    print(f'Outer fold {i + 1}')\n",
    "    class_A_test_indices = test_indices[y[test_indices] == chosen_classes[0]]\n",
    "    class_B_test_indices = test_indices[y[test_indices] == chosen_classes[1]]\n",
    "    if len(chosen_classes) == 3:\n",
    "        class_C_test_indices = test_indices[y[test_indices] == chosen_classes[2]]\n",
    "\n",
    "    move_epochs(X, outer_train_indices, cv_path + '/All Data/Stacked scalograms', cv_path + '/Outer Train/All Train', 'epoch_{}-' + file_pattern, copy=True)\n",
    "    move_epochs(X, class_A_test_indices, cv_path + '/All Data/Stacked scalograms', cv_path + '/Test/A', 'epoch_{}-' + file_pattern, copy=True)\n",
    "    move_epochs(X, class_B_test_indices, cv_path + '/All Data/Stacked scalograms', cv_path + '/Test/B', 'epoch_{}-' + file_pattern, copy=True)\n",
    "    if len(chosen_classes) == 3:\n",
    "        move_epochs(X, class_C_test_indices, cv_path + '/All Data/Stacked scalograms', cv_path + '/Test/C', 'epoch_{}-' + file_pattern, copy=True)\n",
    "\n",
    "    inner_results['mean_validation_accuracy'] = 0.0\n",
    "    y_outer_train = y[outer_train_indices]  # Get labels for outer training set\n",
    "    for j, (inner_train_indices, valid_indices) in enumerate(inner_cv.split(outer_train_indices, y_outer_train)):\n",
    "        print(f'  Inner fold {j + 1}')\n",
    "        class_A_train_indices = outer_train_indices[inner_train_indices[y_outer_train[inner_train_indices] == chosen_classes[0]]]\n",
    "        class_B_train_indices = outer_train_indices[inner_train_indices[y_outer_train[inner_train_indices] == chosen_classes[1]]]\n",
    "        class_A_valid_indices = outer_train_indices[valid_indices[y_outer_train[valid_indices] == chosen_classes[0]]]\n",
    "        class_B_valid_indices = outer_train_indices[valid_indices[y_outer_train[valid_indices] == chosen_classes[1]]]\n",
    "        if len(chosen_classes) == 3:\n",
    "            class_C_train_indices = outer_train_indices[inner_train_indices[y_outer_train[inner_train_indices] == chosen_classes[2]]]\n",
    "            class_C_valid_indices = outer_train_indices[valid_indices[y_outer_train[valid_indices] == chosen_classes[2]]]\n",
    "        \n",
    "        move_epochs(X, class_A_train_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train/Train/A', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        move_epochs(X, class_B_train_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train/Train/B', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        move_epochs(X, class_A_valid_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train/Valid/A', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        move_epochs(X, class_B_valid_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train/Valid/B', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        if len(chosen_classes) == 3:\n",
    "            move_epochs(X, class_C_train_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train/Train/C', 'epoch_{}-' + file_pattern, copy=True)\n",
    "            move_epochs(X, class_C_valid_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train/Valid/C', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        train_path = cv_path + '/Outer Train'\n",
    "        \n",
    "        # Perform model training for each of the hyperparameters and track the results in some sort of table\n",
    "        for optimizer in optimizers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    row = (\n",
    "                        (inner_results['optimizer'] == optimizer) &\n",
    "                        (inner_results['learning_rate'] == learning_rate) &\n",
    "                        (inner_results['batch_size'] == batch_size)\n",
    "                    )\n",
    "                    inner_results.loc[row, 'mean_validation_accuracy'] += NeuralNetworks.train_model(\n",
    "                        model_name, train_path, optimizer, learning_rate, batch_size\n",
    "                    )\n",
    "        \n",
    "        # Delete all files in the train and valid folders\n",
    "        delete_all_files_in_folder(cv_path + '/Outer Train/Train/A')\n",
    "        delete_all_files_in_folder(cv_path + '/Outer Train/Train/B')\n",
    "        delete_all_files_in_folder(cv_path + '/Outer Train/Valid/A')\n",
    "        delete_all_files_in_folder(cv_path + '/Outer Train/Valid/B')\n",
    "        if len(chosen_classes) == 3:\n",
    "            delete_all_files_in_folder(cv_path + '/Outer Train/Train/C')\n",
    "            delete_all_files_in_folder(cv_path + '/Outer Train/Valid/C')\n",
    "\n",
    "    # Calculate the mean validation accuracy for each hyperparameter combination\n",
    "    inner_results['mean_validation_accuracy'] /= inner_cv.get_n_splits()\n",
    "    if len(chosen_classes) == 2:\n",
    "        inner_results.to_csv(results_path+ f'/{chosen_classes[0]}_vs_{chosen_classes[1]}_inner_results_fold_{i + 1}.csv', index=False)\n",
    "    else:\n",
    "        inner_results.to_csv(results_path+ f'/All_Classes_inner_results_fold_{i + 1}.csv', index=False)\n",
    "    # Find the best hyperparameters based on the mean validation accuracy\n",
    "    best_hyperparams = inner_results.loc[inner_results['mean_validation_accuracy'].idxmax()]\n",
    "    print(f'Best hyperparameters for outer fold {i + 1}: {best_hyperparams.to_dict()}')\n",
    "    \n",
    "    # Split the outer training set into train and valid sets for retraining of final model\n",
    "    retrain_split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_indices, valid_indices in retrain_split.split(outer_train_indices, y_outer_train):\n",
    "        class_A_train_indices = outer_train_indices[train_indices[y_outer_train[train_indices] == chosen_classes[0]]]\n",
    "        class_B_train_indices = outer_train_indices[train_indices[y_outer_train[train_indices] == chosen_classes[1]]]\n",
    "        class_A_valid_indices = outer_train_indices[valid_indices[y_outer_train[valid_indices] == chosen_classes[0]]]\n",
    "        class_B_valid_indices = outer_train_indices[valid_indices[y_outer_train[valid_indices] == chosen_classes[1]]]\n",
    "        if len(chosen_classes) == 3:\n",
    "            class_C_train_indices = outer_train_indices[train_indices[y_outer_train[train_indices] == chosen_classes[2]]]\n",
    "            class_C_valid_indices = outer_train_indices[valid_indices[y_outer_train[valid_indices] == chosen_classes[2]]]\n",
    "        \n",
    "        move_epochs(X, class_A_train_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train' + '/Train/A', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        move_epochs(X, class_B_train_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train' + '/Train/B', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        move_epochs(X, class_A_valid_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train' + '/Valid/A', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        move_epochs(X, class_B_valid_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train' + '/Valid/B', 'epoch_{}-' + file_pattern, copy=True)\n",
    "        if len(chosen_classes) == 3:\n",
    "            move_epochs(X, class_C_train_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train' + '/Train/C', 'epoch_{}-' + file_pattern, copy=True)\n",
    "            move_epochs(X, class_C_valid_indices, cv_path + '/Outer Train' + '/All Train', cv_path + '/Outer Train' + '/Valid/C', 'epoch_{}-' + file_pattern, copy=True)\n",
    "\n",
    "    # Retrain the model with the best hyperparameters on the training and validation sets\n",
    "    NeuralNetworks.train_model(model_name,\n",
    "                               cv_path + '/Outer Train',\n",
    "                               optimizer=best_hyperparams['optimizer'],\n",
    "                               learning_rate=float(best_hyperparams['learning_rate']),\n",
    "                               bs=int(best_hyperparams['batch_size']),\n",
    "                               save_model=True)\n",
    "    \n",
    "    # Delete all files in the train and valid folders\n",
    "    delete_all_files_in_folder(cv_path + '/Outer Train' + '/Train/A')\n",
    "    delete_all_files_in_folder(cv_path + '/Outer Train' + '/Train/B')\n",
    "    delete_all_files_in_folder(cv_path + '/Outer Train' + '/Valid/A')\n",
    "    delete_all_files_in_folder(cv_path + '/Outer Train' + '/Valid/B')\n",
    "    if len(chosen_classes) == 3:\n",
    "        delete_all_files_in_folder(cv_path + '/Outer Train' + '/Train/C')\n",
    "        delete_all_files_in_folder(cv_path + '/Outer Train' + '/Valid/C')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    current_final_model_accuracy, conf_mat, clssf_rep = \\\n",
    "        NeuralNetworks.evaluate_final_model(model_name=model_name, \n",
    "                                            test_path=cv_path + '/Test',\n",
    "                                            model_path='final_model.pt',\n",
    "                                            num_classes=len(chosen_classes))\n",
    "    \n",
    "    if len(chosen_classes) == 2:\n",
    "        np.savetxt(results_path + f'/{chosen_classes[0]}_vs_{chosen_classes[1]}_confusion_matrix_{i + 1}.csv', conf_mat, delimiter=',', fmt='%d')\n",
    "        with open(results_path + f'/{chosen_classes[0]}_vs_{chosen_classes[1]}_classification_report_{i + 1}.txt', 'w') as f:\n",
    "            f.write(clssf_rep)\n",
    "    else:\n",
    "        np.savetxt(results_path + f'/All_Classes_confusion_matrix_{i + 1}.csv', conf_mat, delimiter=',', fmt='%d')\n",
    "        with open(results_path + f'/All_Classes_classification_report_{i + 1}.txt', 'w') as f:\n",
    "            f.write(clssf_rep)\n",
    "    final_model_mean_accuracy += current_final_model_accuracy\n",
    "    print(f'Final model accuracy for current outer fold: {current_final_model_accuracy:.4f}')\n",
    "    \n",
    "    # Delete all files in the outer train and test folders\n",
    "    delete_all_files_in_folder(cv_path + '/Outer Train/All Train')\n",
    "    delete_all_files_in_folder(cv_path + '/Test/A')\n",
    "    delete_all_files_in_folder(cv_path + '/Test/B')\n",
    "    if len(chosen_classes) == 3:\n",
    "        delete_all_files_in_folder(cv_path + '/Test/C')\n",
    "\n",
    "\n",
    "# Calculate the mean accuracy across all outer folds\n",
    "final_model_mean_accuracy /= outer_cv.get_n_splits()\n",
    "\n",
    "# Save the final model mean accuracy to a file\n",
    "if len(chosen_classes) == 2:\n",
    "    with open(results_path + f'/{chosen_classes[0]}_vs_{chosen_classes[1]}_final_model_mean_accuracy.txt', 'w') as f:\n",
    "        f.write(f'Mean accuracy of the final model across all outer folds: {final_model_mean_accuracy:.4f}\\n')\n",
    "else:\n",
    "    with open(results_path + f'/All_Classes_final_model_mean_accuracy.txt', 'w') as f:\n",
    "        f.write(f'Mean accuracy of the final model across all outer folds: {final_model_mean_accuracy:.4f}\\n')\n",
    "print(f'Mean accuracy of the final model across all outer folds: {final_model_mean_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
